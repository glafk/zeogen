{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\tue\\\\Thesis\\\\zeogen\\\\data\\\\zeonet_data\\\\DDR', 'c:\\\\tue\\\\Thesis\\\\zeogen\\\\data\\\\zeonet_data\\\\DDRch1', 'c:\\\\tue\\\\Thesis\\\\zeogen\\\\data\\\\zeonet_data\\\\DDRch2', 'c:\\\\tue\\\\Thesis\\\\zeogen\\\\data\\\\zeonet_data\\\\FAU', 'c:\\\\tue\\\\Thesis\\\\zeogen\\\\data\\\\zeonet_data\\\\FAUch', 'c:\\\\tue\\\\Thesis\\\\zeogen\\\\data\\\\zeonet_data\\\\ITW', 'c:\\\\tue\\\\Thesis\\\\zeogen\\\\data\\\\zeonet_data\\\\MEL', 'c:\\\\tue\\\\Thesis\\\\zeogen\\\\data\\\\zeonet_data\\\\MELch', 'c:\\\\tue\\\\Thesis\\\\zeogen\\\\data\\\\zeonet_data\\\\MFI', 'c:\\\\tue\\\\Thesis\\\\zeogen\\\\data\\\\zeonet_data\\\\MOR', 'c:\\\\tue\\\\Thesis\\\\zeogen\\\\data\\\\zeonet_data\\\\RHO', 'c:\\\\tue\\\\Thesis\\\\zeogen\\\\data\\\\zeonet_data\\\\TON', 'c:\\\\tue\\\\Thesis\\\\zeogen\\\\data\\\\zeonet_data\\\\TON2', 'c:\\\\tue\\\\Thesis\\\\zeogen\\\\data\\\\zeonet_data\\\\TON3', 'c:\\\\tue\\\\Thesis\\\\zeogen\\\\data\\\\zeonet_data\\\\TON4', 'c:\\\\tue\\\\Thesis\\\\zeogen\\\\data\\\\zeonet_data\\\\TONch']\n",
      "Loading atoms from c:\\tue\\Thesis\\zeogen\\data\\zeonet_data\\DDR...\n",
      "Loading atoms from c:\\tue\\Thesis\\zeogen\\data\\zeonet_data\\DDRch1...\n",
      "Loading atoms from c:\\tue\\Thesis\\zeogen\\data\\zeonet_data\\DDRch2...\n",
      "Loading atoms from c:\\tue\\Thesis\\zeogen\\data\\zeonet_data\\FAU...\n",
      "Loading atoms from c:\\tue\\Thesis\\zeogen\\data\\zeonet_data\\FAUch...\n",
      "Loading atoms from c:\\tue\\Thesis\\zeogen\\data\\zeonet_data\\ITW...\n",
      "Loading atoms from c:\\tue\\Thesis\\zeogen\\data\\zeonet_data\\MEL...\n",
      "Loading atoms from c:\\tue\\Thesis\\zeogen\\data\\zeonet_data\\MELch...\n",
      "Loading atoms from c:\\tue\\Thesis\\zeogen\\data\\zeonet_data\\MFI...\n",
      "Loading atoms from c:\\tue\\Thesis\\zeogen\\data\\zeonet_data\\MOR...\n",
      "Loading atoms from c:\\tue\\Thesis\\zeogen\\data\\zeonet_data\\RHO...\n",
      "Loading atoms from c:\\tue\\Thesis\\zeogen\\data\\zeonet_data\\TON...\n",
      "Loading atoms from c:\\tue\\Thesis\\zeogen\\data\\zeonet_data\\TON2...\n",
      "Loading atoms from c:\\tue\\Thesis\\zeogen\\data\\zeonet_data\\TON3...\n",
      "Loading atoms from c:\\tue\\Thesis\\zeogen\\data\\zeonet_data\\TON4...\n",
      "Loading atoms from c:\\tue\\Thesis\\zeogen\\data\\zeonet_data\\TONch...\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def process_zeolite_data():\n",
    "    current_dir = os.getcwd()\n",
    "    \n",
    "    # Get all child directories of the current directory\n",
    "    child_dirs = [os.path.join(current_dir, d) for d in os.listdir(current_dir) if os.path.isdir(os.path.join(current_dir, d))]\n",
    "    \n",
    "    print(child_dirs)\n",
    "    for child_dir in child_dirs:\n",
    "        # Check if 'atoms.npy', 'X.npy', 'hoa.npy', 'angles.npy', and 'l.npy' files exist in the child directory\n",
    "        if all(os.path.exists(os.path.join(child_dir, file)) for file in [\"atoms.npy\", \"X.npy\", \"hoa.npy\", \"angles.npy\", \"l.npy\"]):\n",
    "            print(f\"Loading atoms from {child_dir}...\")\n",
    "            \n",
    "            atoms = np.load(os.path.join(child_dir, \"atoms.npy\"))\n",
    "            X = np.load(os.path.join(child_dir, \"X.npy\"))\n",
    "            hoa = np.load(os.path.join(child_dir, \"hoa.npy\"))\n",
    "            angles = np.load(os.path.join(child_dir, \"angles.npy\"))\n",
    "            lengths = np.load(os.path.join(child_dir, \"l.npy\"))\n",
    "            \n",
    "            # Replace values in the atoms object with 13 where there is 1 and 14 where there is 0\n",
    "            atoms = np.where(atoms == 1, 13, np.where(atoms == 0, 14, atoms))\n",
    "            frac_coords = [X] * len(atoms)\n",
    "            angles = [angles] * len(atoms)\n",
    "            lengths = [lengths] * len(atoms)\n",
    "            \n",
    "            crystal_list = []\n",
    "            \n",
    "            for i in range(len(frac_coords)):\n",
    "                data = {\n",
    "                    'frac_coords': frac_coords[i],\n",
    "                    'atom_types': atoms[i],\n",
    "                    'lengths': lengths[i],\n",
    "                    'angles': angles[i],\n",
    "                    'hoa': hoa[i],\n",
    "                    'zeolite_code': os.path.basename(child_dir)\n",
    "                }\n",
    "                \n",
    "                crystal_list.append(data)\n",
    "            \n",
    "            zeolite_code = os.path.basename(child_dir)\n",
    "            \n",
    "            # Save the data to a pickle file called {zeolite_code}_data.pickle\n",
    "            with open(os.path.join(child_dir, f\"{zeolite_code}_data.pkl\"), \"wb\") as f:\n",
    "                pickle.dump(crystal_list, f)\n",
    "            \n",
    "            # Split the data into train, validation and test sets and save them to pickle files\n",
    "            with open(os.path.join(child_dir, f\"{zeolite_code}_data.pkl\"), \"rb\") as f:\n",
    "                data = pickle.load(f)\n",
    "                \n",
    "                # Calculate how many samples from the list need to be in each set based on 60/20/20 split\n",
    "                train_size = int(0.6 * len(data))\n",
    "                val_size = int(0.2 * len(data))\n",
    "                test_size = len(data) - train_size - val_size\n",
    "                \n",
    "                # Split the data into train, validation and test sets\n",
    "                train_data = data[:train_size]\n",
    "                val_data = data[train_size:train_size + val_size]\n",
    "                test_data = data[train_size + val_size:]\n",
    "                \n",
    "                # Save the data to pickle files\n",
    "                with open(os.path.join(child_dir, f\"{zeolite_code}_train.pkl\"), \"wb\") as f:\n",
    "                    pickle.dump(train_data, f)\n",
    "                \n",
    "                with open(os.path.join(child_dir, f\"{zeolite_code}_val.pkl\"), \"wb\") as f:\n",
    "                    pickle.dump(val_data, f)\n",
    "                \n",
    "                with open(os.path.join(child_dir, f\"{zeolite_code}_test.pkl\"), \"wb\") as f:\n",
    "                    pickle.dump(test_data, f)\n",
    "\n",
    "# Example usage\n",
    "process_zeolite_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', ['DDR', 'DDRch1', 'DDRch2', 'FAU', 'FAUch', 'ITW', 'MEL', 'MELch', 'MFI', 'MOR', 'RHO', 'TON', 'TON2', 'TON3', 'TON4', 'TONch'], ['process_zeonet_data.ipynb']), ('.\\\\DDR', [], ['.DS_Store', 'adj.npy', 'angles.npy', 'atoms.npy', 'hoa.npy', 'l.npy', 'X.npy']), ('.\\\\DDRch1', [], ['adj.npy', 'angles.npy', 'atoms.npy', 'hoa.npy', 'l.npy', 'X.npy']), ('.\\\\DDRch2', [], ['adj.npy', 'angles.npy', 'atoms.npy', 'hoa.npy', 'l.npy', 'X.npy']), ('.\\\\FAU', [], ['.DS_Store', 'adj.npy', 'angles.npy', 'atoms.npy', 'hoa.npy', 'l.npy', 'X.npy']), ('.\\\\FAUch', [], ['.DS_Store', 'adj.npy', 'angles.npy', 'atoms.npy', 'hoa.npy', 'l.npy', 'X.npy']), ('.\\\\ITW', [], ['adj.npy', 'angles.npy', 'atoms.npy', 'henry.npy', 'hoa.npy', 'hoa_err.npy', 'l.npy', 'X.npy']), ('.\\\\MEL', [], ['.DS_Store', 'adj.npy', 'angles.npy', 'atoms.npy', 'hoa.npy', 'l.npy', 'X.npy']), ('.\\\\MELch', [], ['adj.npy', 'angles.npy', 'atoms.npy', 'hoa.npy', 'l.npy', 'X.npy']), ('.\\\\MFI', [], ['adj.npy', 'angles.npy', 'atoms.npy', 'henry.npy', 'hoa.npy', 'hoa_err.npy', 'l.npy', 'X.npy']), ('.\\\\MOR', [], ['adj.npy', 'adj.txt', 'adj_pore.csv', 'angles.npy', 'atoms.npy', 'henry.npy', 'hoa.npy', 'hoa_err.npy', 'l.npy', 'X.npy']), ('.\\\\RHO', [], ['adj.npy', 'angles.npy', 'atoms.npy', 'henry.npy', 'hoa.npy', 'hoa_err.npy', 'l.npy', 'X.npy']), ('.\\\\TON', [], ['.DS_Store', 'adj.npy', 'angles.npy', 'atoms.npy', 'hoa.npy', 'l.npy', 'X.npy']), ('.\\\\TON2', [], ['.DS_Store', 'adj.npy', 'angles.npy', 'atoms.npy', 'hoa.npy', 'l.npy', 'X.npy']), ('.\\\\TON3', [], ['adj.npy', 'angles.npy', 'atoms.npy', 'hoa.npy', 'l.npy', 'X.npy']), ('.\\\\TON4', [], ['adj.npy', 'angles.npy', 'atoms.npy', 'hoa.npy', 'l.npy', 'X.npy']), ('.\\\\TONch', [], ['adj.npy', 'angles.npy', 'atoms.npy', 'hoa.npy', 'l.npy', 'X.npy'])]\n",
      "c:\\tue\\Thesis\\zeogen\\data\\zeonet_data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(list(os.walk(\".\")))\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"FAU\", f\"FAU_test.pkl\"), \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
